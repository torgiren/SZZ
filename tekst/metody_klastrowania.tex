\chapter{Metody klastrowania}
W rozdziale tym przedstawię podstawowe metody wykorzystywane przy tworzeniu klastrów pod aplikacje internetowe.
\section{DNS round robin}
\subsection{Czym jest DNS}
DNS (ang {\textit{Domain Name System}) jest to system nazw domenowych. Usługa której najważniejszą funkcją jest przyporządkowanie nazwom domenowym (czytelnym dla człowieka) adresów IP.
Oznacza to, że system taki, jest w stanie zamienić nazwę \texttt{www.ftj.agh.edu.pl} na adres \texttt{149.156.110.3}.
Funkcjonalność taka w znacznym stopniu ułatwia korzystanie z sieci Internet, ponieważ przeciętnemu człowiekowi jest prościej zapamiętać mnemonik \texttt{www.ftj.agh.edu.pl} bądź \texttt{www.duckduckgo.com} niż ciągi czterech liczb.
Do zamiany nazwy domenowej na adres IP służą rekordy \texttt{A} oraz \texttt{AAAA}, wykorzystywane odpowiednio do adresów IPv4 oraz IPv6.
Przykład zastosowania rekordu \texttt{A} przedstawiam na poniższym listingu:
\lstinputlisting{lst/rr_arecord.lst}
w powyżej konfiguracji widzimy, że odpytując server DNS o wartość \texttt{nazwa4.domenowa.pl} otrzymamy informację, że dana nazwa wskazuje na adres \texttt{1.2.3.4}.\\
Innymi, często spotykanymi rekordami są rekordy \texttt{CNAME}, \texttt{MX} oraz \texttt{TXT}.
\begin{description}
\item[CNAME] jest to rekord będący wskaźnikiem. Dla przykładu:
\lstinputlisting{lst/rr_cname.lst}
widzimy, że w powyższym przykładzie \texttt{nazwa.domenowa.pl} wskazuje na 1.2.3.4.
Chcąc aby, \texttt{www.nazwa.domenowa.pl} również wskazywała w to samo miejsce, moglibyśmy również zdefiniować ją jako rekord \texttt{A} z takim samym adresem.
Jednak, w przypadku migracji serwera z adresu \texttt{1.2.3.4} na \texttt{1.2.3.5}, należałoby zmieniać ten adres w obu rekordach.
Zastosowanie rekordu \texttt{CNAME}, pozwala powiedzieć "nazwa \texttt{www.nazwa.domenowa.pl} wskazuje w to samo miejsce, w które wskazuje \texttt{nazwa.domenowa.pl}".
Prowadzi to do zmniejszenia ryzyka pomyłki przy wpisywaniu adresów IP, jak również zmniejsza liczbę miejsc w których należy zmienić adresację w przypadku migracji serwera.
\item[MX] rekord wskazujący na adres serwera pocztowego obsługującego daną domenę.
Strefa może zawierać kilka rekordów \texttt{MX} w celu dystrybucji ruchu na kilka serwerów pocztowych.
\lstinputlisting{lst/rr_mxrecord.lst}
Widzimy, że wpis definiujący rekord \texttt{MX} nie posiada nazwy. Zwykle rekord ten definiowany jest na początku definicji strefy, dlatego pominięcie nazwy powoduje, ze rekord ten odnosi się do nazwy tej strefy.
Jest to kolejna rzecz które uogólnia konfigurację i ułatwia migrowanie.
Wartość \texttt{5} oznacza poziom preferencji danego serwera. Mając zdefiniowanych kilka rekordów \texttt{MX}, poczta jest dystrybuowana przy pomocy algorytmu ważonego round robin.
\item[TXT] rekord który zgodnie z założeniami DNS miał zawierać dane tekstowe czytelne dla człowieka.
Obecnie rzadko zawiera dane dla użytkowników. Wykorzystywany jest głównie do konfiguracji SPF, co wykracza poza tematykę tej pracy.
\end{description}
\subsection{Opis metody}
Metoda ta polega na odpowiednim skonfigurowaniu strefy na serwerze DNS, w taki sposób, aby pod jedna nazwa rozwiązywała się na kilka adresów IP.
W efekcie, gdy serwer otrzyma zapytanie o daną nazwę domenową, zostanie mu zwrócona pula adresów zamiast jednego.
Aplikacja która otrzyma listę adresów IP, powinna połączyć się na losowy z nich.
Niestety nigdy nie ma pewności, że aplikacja posiada zaimplementowaną obsługę wielu adresów zwracanych przez serwer DNS, dlatego serwer wprowadza zabezpieczenie przed takim zachowaniem, a mianowicie tytułowy algorytm \textit{round robin}, który zwraca adresy IP, jednak za każdym razem ich permutację.\\
Dla przykładu, poniżej zamieszczone trzy zapytania wykonane po sobie.
\lstinputlisting{lst/rr_dig.shell}
Widzimy, że przy każdym zapytaniu, jako pierwszy adres zwracany jest kolejny adres z puli. Zapewnia to prawidłowe balansowanie ruchu, nawet przy aplikacjach nie potrafiących obsłużyć wielu adresów i łączących się na pierwszy otrzymany.

Metoda ta jest metodą wysokiej wydajności, ponieważ pozwala w sposób niewidoczny dla użytkownika rozdzielić ruch na kilka serwerów, a tym samym rozłożyć obciążenie, to skutkować będzie szybszą odpowiedzią klientowi na zapytanie.
Metoda ta nie zapewnia natywnie wykrywania niedostępności któregoś z serwerów, dlatego nie może służyć bezpośrednio jako metoda wysokiej dostępności.
Pośrednio występuje tutaj jednak mechanizm broniący przed niedostępnością któregoś z serwerów. W przypadku gdy aplikacja próbować się będzie połączyć z losowym adresem z puli, a połączenie nie będzie mogło być nawiązane, osiągnięty zostanie limit czasu połączenia (tzw. \textit{timeout}. W takiej sytuacji, dobrze napisana aplikacja, będzie próbować połączyć się na kolejny adres z puli, w nadziei, że będzie on dostępny.
W takiej sytuacji, połączenie zostanie nawiązane i klient otrzyma odpowiedź, jednak do czasu generowania odpowiedzi, trzeba doliczyć czas potrzebny na osiągnięcie \textit{timeout-u}. Może on wynieść od kilku, do kilkudziesięciu sekund.

Metoda ta jest również zależna od działania serwera DNS.
Najprostszym sposobem ochrony przed awarią tego systemu dystrybucji ruchu jest skonfigurowanie \textit{Secondary DNS}. To jednak wykracza poza tematykę tej pracy.
\subsection{Konfiguracja}
Konfiguracja DNS round robin jest stosunkowo prosta.
W konfiguracji strefy, należy umieścić wpis z wieloma rekordami \textit{A} dla jednej nazwy.
Przykład takiej strefy zamieszczony został poniżej
\lstinputlisting[caption=mgr.fabrykowski.pl.zone]{lst/rr_zone.zone}
W powyższym przykładzie, dla nazwy \texttt{rr.mgr.fabrykowski.pl} zostały zdefiniowane trzy adresy IP.
\section{Nginx}
\subsection{Czym jest nginx}
Nginx jest serwerem proxy oraz serwerem treści statycznych.
Wykorzystywany jest zwykle w połączeniu z serwerem Apache który serwuje treści PHP, podczas gdy sam dostarcza pliki statyczne (JavaScript, CSS, JPEG itp).
Drugim często wykorzystywanym modelem wykorzystania Nginx-a jest serwowanie treści statycznych oraz wykonywanie \textit{fastcgi pass}
\paragraph{Fastcgi pass} \hspace{0pt} \\
Moduł ten pozwala na komunikacje z procesami FastCGI.
Wykorzystanie FastCGI daje dużą niezależność w technologi opracowania aplikacji, która może zostać wykonana w PHP, Pythonie bądź Rubym.
Istnieje również możliwość zmiany wersji aplikacji, bądź technologii jej wykonania bez zmian w konfiguracji serwera, jeżeli aplikacja udostępnia to samo api FastCGI.

Do obsługi języka PHP zostanie wykorzystany php-fpm (\textit{PHP FastCGI Process Manager}.
Jest to alternatywna implementacja PHP FastCGI.
Pozwala ona na większą kontrolę w zakresie pul procesów - ich liczby oraz sposobu uruchamiania, jak również dowolność w kwestiach sieciowych - adres oraz port do nasłuchiwania.

Porównanie testów wydajności PHP-fpm oraz mod\_php do Apache jak również szybkość serwowania treści statycznych zostanie przedstawione w późniejszych rozdziałach.
\subsection{Opis metody}
Metoda klastrowania przy pomocy Nginx-a polega na zdefiniowaniu sekcji \texttt{upstream}.
Pozwala to na skonfigurowanie puli adresów do których będą przekazywane zapytania.
Aby dodać serwer do puli, należy podać jego adres IP bądź nazwę domenową oraz port.

Zapytania do serwerów wykonujących (\textit{workerów}) rozdzielane są równomiernie pomiędzy wszystkie serwery w puli.\\
Pozwala to na obsługiwanie zapytań na wielu maszynach, dlatego metoda ta pozwala na tworzenie klastrów \textbf{wysokiej wydajności}.

Ponadto, zaimplementowany jest również mechanizm sprawdzający stan poszczególnych serwerów w puli i w przypadku wykrycia awarii, oznaczany jest on jaki \textit{failure} i zapytanie nie są do niego kierowane.\\
Jest to zachowanie typowe dla klastrów \textbf{wysokiej dostępności}

Istnieje możliwość modyfikacji domyślnego algorytmu używanego przez Nginx-a.
\begin{itemize}
	\item zmiana sposobu dystrybucji zapytań dodając opcjonalny parametr \texttt{weight} mówiący o wadze danego węzła. Dla przykładu, w poniższej konfiguracji:
	\lstinputlisting{lst/nx_weight.conf}
	na każde 6 zapytań do \texttt{pula1}, 5 zostanie przekazanych do \texttt{server1} a jedno do \texttt{server2}.
	Opcja ta wykorzystywana jest głównie tam, gdzie poszczególne serwery różnią się parametrami bądź obciążeniem nie wynikającym z obsługiwania tej puli.
	\item zmiana sposobu określania serwera jako niedostępnego.
	Służą do tego parametry \texttt{max\_fails}, \texttt{fail\_timeout} oraz \texttt{slow\_start}.\\
	\begin{description}
	\item[\texttt{max\_fails}] określa liczbę nieudanych prób komunikacji z serwerem w czasie \texttt{fail\_timeout} nim serwer zostanie oznaczony jako niedostępny.
	Domyślna wartość tego parametru wynosi 1, natomiast wartość 0 wyłącza oznaczanie serwerów jako niedostępne.
	\item[\texttt{fail\_timeout}] określa czas w jakim musi nastąpić \texttt{max\_fails} nim serwer zostanie uznany za niedostępny.
	Określa również interwał czasowy co który będzie sprawdzana dostępność serwera.
	Wartość domyślna dla tego parametru wynosi 10 sekund.
	\item[\texttt{slow\_start}] określa czas w jakim będzie zwiększana wartość \texttt{weight} od zera do docelowej po przejściu serwera ze stanu niedostępnego do stanu dostępnego.
	Wartość domyślna wynosi 0, co oznacza wyłączone płynne włączanie serwera do puli.
	\end{description}
	\item oznaczenie konkretnych serwerów, jako serwery zapasowe.  
	Powoduje to nieprzekazywanie zapytań do tych serwerów jeżeli wszystkie serwery podstawowe odpowiadają.
	W przypadku, gdy któryś z podstawowych serwerów zostanie oznaczony jako niedostępny, zapytania zostają przekazywane do któregoś z serwerów zapasowych.
	Powoduje to zachowanie \textbf{wysokiej wydajności} oraz \textbf{wysokiej dostępności}.	
\end{itemize}
\subsection{Konfiguracja}
TODO
\section{Haproxy}
\subsection{Czym jest haproxy}
Haproxy jest serwerem proxy wysokiej dostępności (ang. High Availability Proxy).\\
Posiada on dwie główne funkcjonalności, które czynią go powszechnie używanym narzędziem.
Są nimi:\\
\begin{itemize}
	\item możliwość dystrybuowania ruchu na kilka maszyn, dając tym samym zwiększone możliwości obliczeniowe
	\item wykrywanie awarii serwerów \textit{backendowych} i nieprzekazywaniem do nich zapytań aż do czasu naprawy
\end{itemize}
\subsubsection{Funkcjonalność wysokiej wydajności}
Haproxy pozwala na zdefiniowanie tzw. \textit{backendu}, czyli grupy serwerów pełniących tą samą funkcje.
Decyzja o wyborze serwera dla danego zapytania może być podjęta na podstawie jednego z kilku algorytmów.
Poniżej znajduje się lista kilku najpopularniejszych. Pełną listę można znaleźć w dokumentacji\\
\LARGE TODO - bibliografia\normalsize
\begin{description}
	\item{Round robin}\\
		najpopularniejszy algorytm. Polega na rozdzielaniu zapytam do poszczególnych serwerów "po kolei".
		Kryterium modulującym działanie tego algorytmu jest parametr \texttt{weight}, który jak bardzo dany serwer ma być preferowany.
		Domyślna wartość \texttt{weight} wynosi 1. W przypadku, gdy wszystkie serwery mają takie same wartości, połączenia przekazywane są równo do każdego z nich.
	\item{Leastconn}\\
		wybór serwera podejmowany jest na podstawie ilości aktywnych połączeń do każdej maszyny.
		Wybierany jest serwer z najmniejszą ilością połączeń
	\item{Source}\\
		serwer docelowy wybierany jest na podstawie adresu nadawcy.
		Powoduje to, że jeden klient będzie zawsze obsługiwany przez tą samą maszynę. Pozwala to na uproszczenie obsługi sesji pomiędzy maszynami.
\end{description}
Ponieważ Haproxy działa w warstwie siódmej modelu OSI - czyli w warstwie aplikacji, możliwe jest również decydowanie o wyborze serwera na podstawie nagłówków zapytać HTTP.
Na podstawie np: wartości \texttt{host} w nagłówku HTTP, haproxy jest w stanie nasłuchując na jednym porcie dystrybuować ruch na odpowiednie \textit{backendy} odpowiedzialne za różne strony.
Przykłady takiego zastosowania zostaną przedstawione w podrozdziale "\ref{sec:haproxy_config} Konfiguracja"
\subsubsection{Funkcjonalność wysokiej dostępności}
Możliwości wykrywania niedostępności usługi oraz zapewnienia wysokiej dostępności były głównym celem twórców.
Świadczyć może o tym nazwa - \textit{HAProxy}, pochodzącą od \textit{High Availability} czyli wysoka dostępność.\\
Domyślnie haproxy nie sprawdza dostępności serwerów. Aby włączać tą funkcjonalność należy użyć parametru \texttt{check}.\\
\texttt{Check} sprawdza pod adresem i portem zdefiniowanymi dla danego serwera udaje się ustanowić połączenie TCP.
Jeśli tak jest, usługa jest uznawana za działającą i połączenia są kierowane na daną maszynę.\\
Istnieją również inne predefiniowane funkcje sprawdzające, np: \texttt{httpcheck} służący do sprawdzania odpowiedzi serwera WWW pod zadanym \texttt{uri}, \texttt{smtpcheck} - sprawdza usługę \texttt{smtp}, \texttt{mysql-check} oraz \texttt{pgsql-check} do baz danych.
Istnieje również możliwość stworzenia własnych mechanizmów sprawdzających działanie usługi, bazujące na technologii \texttt{expect}.
\subsection{Konfiguracja}
\label{sec:haproxy_config}
Na listingu  \ref{lst:haproxy_config} przedstawiono przykładową konfigurację HAProxy obsługującą zarówno wiele adresów url jak również stanowi \textit{frontend} dla \texttt{php-fpm}.
\lstinputlisting[caption=haproxy.cfg,label=lst:haproxy_config]{lst/haproxy_config.cfg}
W konfiguracji \textit{haproxy} wyróżniamy następujące ważne sekcje:
\begin{description}
	\item{\texttt{global}}\\
		zawiera konfigurację ustawień dla procesu haproxy.
		Umieszczane są tutaj informacje o ilości maksymalnych połączeń do procesu, \texttt{uid}-dzie bądź nazwie użytkownika i grupy z jakim należy uruchomić aplikacje, ścieżka do pliku z numerami \texttt{PID} procesów haproxy.
	\item{\texttt{defaults}}\\
		sekcja ta zawiera wartości domyślne dla innych sekcji.
		Pozwala to na umieszczenie dużej części konfiguracji w jednym miejscu, co ułatwia zarządzanie nią.
		Wartości zdefiniowane w sekcji \texttt{defaults} mogą być nadpisane w konkretnej sekcji wartością specyficzną dla danej sekcji.\\
		Dla przykładu, można zdefiniować domyślną wartość \texttt{timeout} na 10 sekund, natomiast dla pewnego serwisu, który wykonuje długotrwałe obliczenia, można tą wartość nadpisać wartości większa.
		Podejście takie pozwala na zachowanie zabezpieczenia przed nieodpowiadającymi procesami dla wszystkich serwisów, jednocześnie zezwalając aby serwis wykonujący długotrwałe obliczenia nie był anulowany przed uzyskaniem wyniku.
	\item{\texttt{listen}}\\
		definiuje usługę wysokiej dostępności. Po słowie kluczowym \texttt{listen} następuje nazwa danej usługi a następnie adres IP oraz port na którym będzie nasłuchiwać dana usługa.\\
		Słowo kluczowe \texttt{mode} definiuje w jakim trybie ma działać dana usługa.
		Wyróżniamy dwa tryby:
		\begin{itemize}
			\item \texttt{http}\\
				tryb ten działa w warstwie siódmej i pozwala na operowanie na zmiennych zawartych w nagłówkach HTTP
			\item \texttt{tcp}\\
				tryb ten działa w warstwie czwartej i powinien być stosowany do wszystkich połączeń nie będących połączeniami HTTP, tj. SSH, SSL i inne.
		\end{itemize}
		Historycznie istniał jeszcze tryb \texttt{health}, jednak jest już przestarzały i nie zalecane jest jego używanie.\\
		W przykładzie na listingu \ref{lst:haproxy_config} w usłudze \texttt{stats} znajdują się polecenia dające dostęp administratorowi do statystyk haproxy.
		W ich skład wchodzi m.in:
		\begin{itemize}
			\item ilość wszystkich połączeń przyjętych na dany \textit{frontend}
			\item ilość aktywnych połączeń na \textit{frontendach}
			\item stan serwerów obsługujących \textit{backendy}
			\item ilości połączeń na każdy serwer w \textit{backendach}
		\end{itemize}
		W przypadku większych instalacji, bądź potrzeby posiadania większej kontroli nad sposobem \textit{load balncingu} stosuje się strukturę rozbijającą prosty \texttt{listen} na dwie sekcje: \texttt{frontend} oraz \texttt{backend}.
	\item{\texttt{frontend}}\\
		\texttt{Frontend} odpowiedzialny jest za przyjmowanie i analizę połączeń od użytkownika.
		W sekcji tej znajduje znajduje się podzbiór poleceń z sekcji \texttt{listen} dotyczących opcji nasłuchiwania, takich jak adres oraz port, sposobu traktowania ruchu (http, tcp) jak również polecenia mogące analizować ruch w celu odpowiedniego jego obsłużenia.
		Noszą one nazwę \textit{ACL (and. Access Control List)}.
		Reguły ACL potrafią analizować ruch począwszy od warstwy czwartej do warstwy siódmej.\\
		Dla ruchu HTTP istnieje możliwość analizy nagłówków oraz rozdział połączań na różne serwery w zależności od pola \texttt{Host}, adresu \texttt{url} bądź metody żądania.
		Dla ruchu HTTPS istnieje możliwość konfiguracji ACL dla żądanego hosta dzięki technologi SNI \textit{ang. Server Name Indication} - technologia pozwalająca na odczytywanie wartości żądanego hosta w połączeniach HTTPS.
		Wykorzystywana w celu uruchamiania wielu adresów WWW na jednym porcie przy szyfrowaniu SSL.\\
		Po zdefiniowaniu ACL, istnieje możliwość zdefiniowania użycia konkretnego \texttt{backend}-u w zależności od przypisania do ACL.\\
		Dodatkowo, oprócz wyboru odpowiedniego \texttt{backend}-u istnieje możliwość odrzucania połączeń spełniających warunki ACL - np: zbyt duża ilość połączeń.
	\item{\texttt{backend}}\\
		Sekcja ta definiuje zaplecze serwerowe, tj. listę serwerów do których ma być kierowany ruch.
		Są tutaj w mocy wszystkie polecenia które mogą znaleźć się w sekcji \texttt{listen} które tyczą się serwerów obsługujących, czyli m.in. algorytm rozdziału połączeń czy specyficzne metody sprawdzania dostępności serwera.
\end{description}
\section{LVS}
\subsection{Czym jest LVS}
LVS (\textit{ang. Linux Virtual Server}) jest technologią pozwalającą na tworzenie klastrów bazujących na systemach GNU/Linux.
Metoda ta jest bardzo wysoko skalowalna przy małym obciążeniu procesora.\\
Trzeba mieć na uwadze, że LVS nie możliwości współbieżnego przetwarzania operacji, a jedynie dystrybucję połączeń pomiędzy wiele serwerów.
\subsection{Opis metody}
LVS jest technologią działającą w czwartej warstwie modelu OSI, tj. w warstwie transportowej.
Zakłada ona istnienie dwóch typów serwerów w klastrze:
\begin{description}
	\item{\textit{Director}}\\
		Jest to serwer zarządzający. Występuje jeden w klastrze.
		To do niego kierowane są połączenia klienckie.
	\item{\textit{Real Server}}\\
		Jest to serwer z właściwą usługą. W klastrze może występować ich wiele.
		Odpowiedzialne są za przetwarzanie zapytań od klienta.
\end{description}
LVS może działać w jednym z trzech trybów:
\begin{description}
	\item{\textit{NAT}}\\
		W tym trybie zapytania przychodzące od klienta do \textit{Directora} zostają znatowane na adres jednego z \textit{Real server}-ów.
		Po obsłużeniu zapytania, \textit{real server} przekazuje odpowiedź do \textit{director}-a który następnie przekazuje odpowiedź do klienta.\\
		Tłumaczenie pakietów wymaga pewnej mocy obliczeniowej, ponadto \textit{director} uczestniczy w przesyłaniu zapytania oraz odpowiedzi, co sprawia, że tryb NAT ma ograniczoną skalowalność ograniczoną mocą procesora oraz łącza internetowego.
	\item{\textit{Direct Routing}}\\
		Tryb ten jest wolny od problemów z mocą obliczeniową oraz utylizacją łącza występujących w przypadku trybu NAT.\\
		W przypadku \textit{direct routing}-u \textit{real server}-y posiadają dodatkowe adresy IP, takie same jak adresy IP używane do \textit{load balancingu} na \textit{directorze} jednak \textit{real server} musi być tak skonfigurowany aby nie odpowiadał na zapytania ARP o te adresy.\\
		Gdy pakiet dochodzi do \textit{directora}, zostaje on przekazany w niezmienionej formie (od trzeciej warstwy wzwyż) do jednego z \textit{real server}-ów. \textit{Director} musi mieć możliwość bezpośredniego połączenia z \textit{real server}-em aby móc opakować pakiet w odnowienie nagłówki warstwy drugiej.
		Ponieważ \textit{real server} posiada dodatkowy adres IP, pakiet przekazany przez \textit{director}-a jest akceptowany ponieważ adres docelowy w pakiecie zgadza się z adresem posiadanym przez \textit{real server}.
		Po przyjęciu pakiety, \textit{real server} odpowiada na niego na adres źródłowy zawarty w pakiecie, czyli bezpośrednio do klienta - omijając \textit{director}-a.
		Następnie, klient wysyłając kolejne kieruje je do \textit{director}-a, który śledząc połączenia, przekazuje je zawsze do odpowiedniego \textit{real server}-a.

		Powyższa procedura powoduje, iż \textit{director} nie jest obciążany obliczaniem adresacji dla NAT, gdyż przekazuje pakiety w niezmienionej formie, oraz zmniejsza utylizacje łącza, ponieważ na łączy \textit{director}-a przesyłane są jedynie pakiety z żądaniami (na wejściu - od klienta, i na wyjściu - do \textit{real server}-a), natomiast pakiety z odpowiedzią, np: HTTP, które są zwykle znacznie większe niż zapytania, są przesyłane łączami używanymi przez \textit{real server}-y.
		W efekcie, metoda ta jest wysoko skalowalna.
	\item{\textit{IP tunneling}}\\
		Tryb ten działa identycznie jak \textit{direct routing}, z tą różnicą, ze \textit{director} oraz \textit{real server}-y nie znajdują się w jednej fizycznej sieci, lecz są spięte jakimś tunelem.
\end{description}

Należy zwrócić uwagę, że LVS nie posiada żadnego wbudowanego systemu zapewniającego wysoką dostępność.
Jest to metoda zapewniająca wyłącznie wysoką wydajność.
Istnieją rozwiązania współpracujące z LVS dodające funkcjonalność wykrywania niedostępności usługi na \textit{real server}-ach i wypinające je z konfiguracji LVS.\\
Te rozwiązania są jednak poza zakresem niniejszej pracy.
\subsection{Konfiguracja}
